{
 "metadata": {
  "name": "",
  "signature": "sha256:36e0519a1debbb1cdcbf883087065944c4cef5dfd762b1f4e747843683371093"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# BigQuery - Using Asynchronous APIs\n",
      "\n",
      "This notebook demonstrates how to use asynchronous versions of the pygcp.bigquery APIs from within a notebook.\n",
      "\n",
      "### In this notebook you will\n",
      "* Learn about the Query and Table APIs that have \\*_async versions\n",
      "* Learn how to use these APIs to return quickly so you can continue to do other work\n",
      "* Learn how to monitor the state of background async tasks and know when they are complete\n",
      "\n",
      "Related Links:\n",
      "\n",
      "* [BigQuery](https://cloud.google.com/bigquery/)\n",
      "\n",
      "----\n",
      "\n",
      "NOTE:\n",
      "\n",
      "* If you're new to notebooks, or want need an introduction to using BigQuery, check out the full [list](..) of notebooks.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gcp.bigquery as bq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Many if the APIs that exist on Query and Table objects in the gcp.bigquery library have async forms.\n",
      "\n",
      "These include:\n",
      "\n",
      "* Query.extract\n",
      "* Query.to_file\n",
      "* Query.execute\n",
      "* Table.load\n",
      "* Table.extract\n",
      "* Table.to_file\n",
      "* View.execute\n",
      "\n",
      "In each case, the signature is exactly the same; the only difference is that the async versions have an \\_async suffix on the method name and return Job objects.\n",
      "\n",
      "For example, the code below will attempt to extract the first 1000 rows of the natality sample table to a temporary file:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = bq.table('publicdata:samples.natality')\n",
      "j = t.sample(count=1000).to_file_async('/tmp/natality1000.csv')\n",
      "j"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Job 9b6925d5-d761-440b-a411-f765fe03b155 in progress"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how the extract\\_async method returned a job with a GUID ID and a status. For a correct job on a very fast \n",
      "machine you may see 'completed' for the job status, but more likely you see 'in progress'.\n",
      "\n",
      "You can always check on the state of a job object by calling its is\\_complete method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.is_complete"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To wait until a job completes we can call wait():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.wait()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "Job 9b6925d5-d761-440b-a411-f765fe03b155 completed"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once it is complete, the fatal\\_error property will tell us if a job failed, while the errors property will inform us of any non-fatal errors that may have occurred:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Fatal: %s\" % str(j.fatal_error)\n",
      "print \"Non-fatal: %s\" % str(j.errors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fatal: None\n",
        "Non-fatal: None\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly, we can call the Job.failed method to test for success:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.failed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "To see what happens with a failing job we can try a similar operation but with an extract usinbg an invalid GCS name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = bq.table('publicdata:samples.natality')\n",
      "j = t.sample(count=1000).extract_async('natality:1000.csv')\n",
      "j"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "Job 0bd58014-8cd6-4c2a-9da9-0c83f6c29c6f failed with error: Invalid extract destination URI 'natality:1000.csv'. Must be a valid Google Storage path."
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how in this case for the job status we got an error message. Once again we can check the errors and status:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Fatal: %s\" % str(j.fatal_error)\n",
      "print \"Non-fatal: %s\" % str(j.errors)\n",
      "print \"Failed: %s\" % j.failed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fatal: Invalid extract destination URI 'natality:1000.csv'. Must be a valid Google Storage path.\n",
        "Non-fatal: None\n",
        "Failed: True\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are two useful utility functions in gcp.bigquery available for working with jobs, namely wait_any and wait_all. Each of these can take a reference to a job, or a list of jobs, plus an optional timeout. wait_any will return when at least one job has completed (or a timeout happens) while wait_all will return when all jobs have completed (or the timeout happens). In each case the return value is the list of complete jobs. We can illustrate this with the following code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q1 = bq.query('SELECT * FROM [publicdata:samples.natality] LIMIT 500')\n",
      "q2 = bq.query('SELECT * FROM [publicdata:samples.natality] LIMIT 5000')\n",
      "j1 = q1.execute_async()\n",
      "j2 = q2.execute_async()\n",
      "\n",
      "while True:\n",
      "    completed = bq.wait_any([j1, j2])\n",
      "    print str(completed)\n",
      "    if len(completed) == 2:\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Job job_uPJOMXmWeF7UggM1ugsv5LH4kdI completed]\n",
        "[Job job_uPJOMXmWeF7UggM1ugsv5LH4kdI completed]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Job job_uPJOMXmWeF7UggM1ugsv5LH4kdI completed]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Job job_uPJOMXmWeF7UggM1ugsv5LH4kdI completed]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Job job_uPJOMXmWeF7UggM1ugsv5LH4kdI completed, Job job_MrGjZYPcfTybk75iG2qNvcKYbhU completed]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}